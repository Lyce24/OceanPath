{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa774bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of samples: 1943\n"
     ]
    }
   ],
   "source": [
    "# add path to the notebook environment\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "data_combined = pd.read_excel('../data/combined_labels_with_patient_id.xlsx')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"Number of samples:\", len(data_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0ecaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_features_mmap] Loading mmap store from: ../../combined_features/wsi_processed_no_penmarks/features_uni_v2/combined_mmap_16\n",
      "[load_features_mmap] 1943 WSIs | feature_dim=1536 | total_patches=23825514\n",
      "[load_features_mmap] Est preload for selected slides: 68.17 GB | Avail RAM: 50.10 GB | decision: INDEX-ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1943/1943 [00:00<00:00, 900500.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_features_mmap] Prepared 1943 slides with indices only. Use mmap slices later to load per-batch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.train_utils import load_features_mmap, prepare_labels\n",
    "\n",
    "encoder = \"uni_v2\"\n",
    "verbose = True\n",
    "precision = 16\n",
    "major_dir = \"../../combined_features/wsi_processed_no_penmarks\"\n",
    "feature_dir = f\"{major_dir}/features_{encoder}\"\n",
    "\n",
    "preloaded_features, D, preloaded = load_features_mmap(data_combined, feature_dir=feature_dir, id_col=\"De-ID\", verbose=verbose, precision=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39c8bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 704 samples with valid labels for task 'Binary Stage N'.\n",
      "Detected 2 classes: [0.0, 1.0]\n",
      "Computed class weights: [1.1578947305679321, 0.8799999952316284]\n",
      "Class distribution -> '0.0' (304), '1.0' (400)\n",
      "Filtered to 175 samples with valid labels for task 'Binary Stage N'.\n",
      "Detected 2 classes: [0.0, 1.0]\n",
      "Computed class weights: [1.75, 0.7000000476837158]\n",
      "Class distribution -> '0.0' (50), '1.0' (125)\n"
     ]
    }
   ],
   "source": [
    "from models.wsi_model import WSIModel\n",
    "\n",
    "encoder_type = \"ABMIL\"  # or \"ABMIL\", \"TransMIL\", \"Mean\", \"Max\", \"WIKGMIL\", \"DSMIL\", \"CLAM\", \"ILRA\"\n",
    "if encoder_type == \"ABMIL\":\n",
    "    encoder_attrs = {\n",
    "        \"attn_dim\": 384,\n",
    "        \"gate\": True\n",
    "    }\n",
    "elif encoder_type == \"TransMIL\":\n",
    "    encoder_attrs = {\n",
    "        \"num_attention_layers\": 2,\n",
    "        \"num_heads\": 4\n",
    "    }\n",
    "elif encoder_type == \"WIKGMIL\":\n",
    "    encoder_attrs = {\n",
    "        \"agg_type\": \"bi-interaction\",\n",
    "        \"pool\": \"attn\",\n",
    "        \"topk\": 4\n",
    "    }\n",
    "elif encoder_type == \"DSMIL\":\n",
    "    encoder_attrs = {\n",
    "        \"attn_dim\": 384,\n",
    "        \"dropout_v\": 0.0\n",
    "    }\n",
    "elif encoder_type == \"CLAM\":\n",
    "    encoder_attrs = {\n",
    "        \"attention_dim\": 384,\n",
    "        \"gate\": True,\n",
    "        \"k_sample\": 8,\n",
    "        \"subtyping\": False,\n",
    "        \"instance_loss_fn\": \"svm\",\n",
    "        \"bag_weight\": 0.7\n",
    "    }\n",
    "else:\n",
    "    encoder_attrs = {}\n",
    "\n",
    "task = \"Binary Stage N\"  # binary_tasks = [\"Binary Stage N\", \"Binary Stage T\", \"Binary TNM Stage\", \"died_within_5_years\", \"MSI\", \"BRAF\", \"KRAS\", \"NRAS\", \"RAS\"]\n",
    "\n",
    "train_df, train_labels, train_class_weights, n_classes, patient_id_mapping = prepare_labels(data_combined, \"De-ID\", task, verbose, cohorts=[\"SR\"], patient_id_col=\"Patient ID\")\n",
    "test_df, test_labels, test_class_weights, _, _ = prepare_labels(data_combined, \"De-ID\", task, verbose, cohorts=[\"RIH\"], patient_id_col=None)\n",
    "train_class_weights = train_class_weights.to(device) if train_class_weights is not None else None\n",
    "test_class_weights = test_class_weights.to(device) if test_class_weights is not None else None\n",
    "\n",
    "n_splits        = 5\n",
    "test_size       = 0.20\n",
    "\n",
    "# Optimizer / LR schedule\n",
    "lr              = 1e-04           # stable with eff. BS=16; see notes for alt\n",
    "l2_reg          = 5e-03           # use param groups: no WD on bias/LayerNorm\n",
    "scheduler       = \"cosine\"\n",
    "epochs          = 40\n",
    "warmup_epochs   = 0              # ~10% of total\n",
    "step_on_epochs  = True           # per-update schedule (correct with accumulation)\n",
    "accum_steps     = 1\n",
    "early_stopping  = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment on Device: cuda ===\n",
      "Train set size: 704\n",
      "Test set size: 175\n",
      "\n",
      "=== Running Experiment with 5-Fold Cross-Validation ===\n",
      "Task: Binary Stage N, Sample Size: 704 (train+val)\n",
      "[Fold 1 | Epoch 5/40] TrainLoss=0.5202 | ValScore=0.7103 | ValLoss=0.8473 | accuracy=0.6000; precision=0.6964; recall=0.5000; f1=0.5821; balanced_accuracy=0.6129; log_loss=0.8473; roc_auc=0.7103\n",
      "[Fold 1 | Epoch 10/40] TrainLoss=0.3024 | ValScore=0.6990 | ValLoss=1.0015 | accuracy=0.7071; precision=0.7126; recall=0.7949; f1=0.7515; balanced_accuracy=0.6958; log_loss=1.0015; roc_auc=0.6990\n",
      "[Fold 1] Early stopping at epoch 11; Saving best model at epoch 3\n",
      "\n",
      "[Fold 1] Best Val Score: 0.7654\n",
      "[Fold 1] [Binary Stage N] accuracy: 0.7357\n",
      "[Fold 1] [Binary Stage N] precision: 0.6990\n",
      "[Fold 1] [Binary Stage N] recall: 0.9231\n",
      "[Fold 1] [Binary Stage N] f1: 0.7956\n",
      "[Fold 1] [Binary Stage N] balanced_accuracy: 0.7115\n",
      "[Fold 1] [Binary Stage N] log_loss: 0.6331\n",
      "[Fold 1] [Binary Stage N] roc_auc: 0.7654\n",
      "\n",
      "[Fold 2 | Epoch 5/40] TrainLoss=0.5193 | ValScore=0.7770 | ValLoss=0.6890 | accuracy=0.7143; precision=0.7590; recall=0.7590; f1=0.7590; balanced_accuracy=0.7041; log_loss=0.6890; roc_auc=0.7770\n",
      "[Fold 2 | Epoch 10/40] TrainLoss=0.2917 | ValScore=0.7811 | ValLoss=0.9768 | accuracy=0.7571; precision=0.7526; recall=0.8795; f1=0.8111; balanced_accuracy=0.7292; log_loss=0.9768; roc_auc=0.7811\n",
      "[Fold 2] Early stopping at epoch 11; Saving best model at epoch 3\n",
      "\n",
      "[Fold 2] Best Val Score: 0.7834\n",
      "[Fold 2] [Binary Stage N] accuracy: 0.7071\n",
      "[Fold 2] [Binary Stage N] precision: 0.7188\n",
      "[Fold 2] [Binary Stage N] recall: 0.8313\n",
      "[Fold 2] [Binary Stage N] f1: 0.7709\n",
      "[Fold 2] [Binary Stage N] balanced_accuracy: 0.6788\n",
      "[Fold 2] [Binary Stage N] log_loss: 0.6281\n",
      "[Fold 2] [Binary Stage N] roc_auc: 0.7834\n",
      "\n",
      "[Fold 3 | Epoch 5/40] TrainLoss=0.5162 | ValScore=0.7788 | ValLoss=0.7501 | accuracy=0.6667; precision=0.6542; recall=0.8750; f1=0.7487; balanced_accuracy=0.6342; log_loss=0.7501; roc_auc=0.7788\n",
      "[Fold 3 | Epoch 10/40] TrainLoss=0.3520 | ValScore=0.7767 | ValLoss=0.9396 | accuracy=0.7376; precision=0.7722; recall=0.7625; f1=0.7673; balanced_accuracy=0.7337; log_loss=0.9396; roc_auc=0.7767\n",
      "[Fold 3 | Epoch 15/40] TrainLoss=0.1000 | ValScore=0.7303 | ValLoss=1.9216 | accuracy=0.7021; precision=0.7639; recall=0.6875; f1=0.7237; balanced_accuracy=0.7044; log_loss=1.9215; roc_auc=0.7303\n",
      "[Fold 3] Early stopping at epoch 15; Saving best model at epoch 7\n",
      "\n",
      "[Fold 3] Best Val Score: 0.7961\n",
      "[Fold 3] [Binary Stage N] accuracy: 0.7163\n",
      "[Fold 3] [Binary Stage N] precision: 0.7439\n",
      "[Fold 3] [Binary Stage N] recall: 0.7625\n",
      "[Fold 3] [Binary Stage N] f1: 0.7531\n",
      "[Fold 3] [Binary Stage N] balanced_accuracy: 0.7091\n",
      "[Fold 3] [Binary Stage N] log_loss: 0.6823\n",
      "[Fold 3] [Binary Stage N] roc_auc: 0.7961\n",
      "\n",
      "[Fold 4 | Epoch 5/40] TrainLoss=0.5096 | ValScore=0.7147 | ValLoss=0.7539 | accuracy=0.6620; precision=0.6667; recall=0.8837; f1=0.7600; balanced_accuracy=0.6026; log_loss=0.7539; roc_auc=0.7147\n",
      "[Fold 4 | Epoch 10/40] TrainLoss=0.3190 | ValScore=0.6607 | ValLoss=1.4718 | accuracy=0.6268; precision=0.7463; recall=0.5814; f1=0.6536; balanced_accuracy=0.6389; log_loss=1.4718; roc_auc=0.6607\n",
      "[Fold 4] Early stopping at epoch 10; Saving best model at epoch 2\n",
      "\n",
      "[Fold 4] Best Val Score: 0.7396\n",
      "[Fold 4] [Binary Stage N] accuracy: 0.6831\n",
      "[Fold 4] [Binary Stage N] precision: 0.7030\n",
      "[Fold 4] [Binary Stage N] recall: 0.8256\n",
      "[Fold 4] [Binary Stage N] f1: 0.7594\n",
      "[Fold 4] [Binary Stage N] balanced_accuracy: 0.6449\n",
      "[Fold 4] [Binary Stage N] log_loss: 0.5913\n",
      "[Fold 4] [Binary Stage N] roc_auc: 0.7396\n",
      "\n",
      "[Fold 5 | Epoch 5/40] TrainLoss=0.5022 | ValScore=0.7210 | ValLoss=0.8070 | accuracy=0.6525; precision=0.6818; recall=0.6164; f1=0.6475; balanced_accuracy=0.6538; log_loss=0.8070; roc_auc=0.7210\n",
      "[Fold 5 | Epoch 10/40] TrainLoss=0.2558 | ValScore=0.6955 | ValLoss=1.1877 | accuracy=0.6241; precision=0.6667; recall=0.5479; f1=0.6015; balanced_accuracy=0.6269; log_loss=1.1877; roc_auc=0.6955\n",
      "[Fold 5] Early stopping at epoch 11; Saving best model at epoch 3\n",
      "\n",
      "[Fold 5] Best Val Score: 0.7234\n",
      "[Fold 5] [Binary Stage N] accuracy: 0.6170\n",
      "[Fold 5] [Binary Stage N] precision: 0.6267\n",
      "[Fold 5] [Binary Stage N] recall: 0.6438\n",
      "[Fold 5] [Binary Stage N] f1: 0.6351\n",
      "[Fold 5] [Binary Stage N] balanced_accuracy: 0.6160\n",
      "[Fold 5] [Binary Stage N] log_loss: 0.6438\n",
      "[Fold 5] [Binary Stage N] roc_auc: 0.7234\n",
      "\n",
      "\n",
      "=== OOF Metrics (5-fold, stratified by label, grouped by patient) ===\n",
      "[Binary Stage N] accuracy: 0.6918\n",
      "[Binary Stage N] precision: 0.7002\n",
      "[Binary Stage N] recall: 0.8000\n",
      "[Binary Stage N] f1: 0.7468\n",
      "[Binary Stage N] balanced_accuracy: 0.6747\n",
      "[Binary Stage N] log_loss: 0.6357\n",
      "[Binary Stage N] roc_auc: 0.7573\n",
      "\n",
      "=== CV Summary Based on Validation Scores ===\n",
      "[Binary Stage N] accuracy: 0.6919 ± 0.0459\n",
      "[Binary Stage N] precision: 0.6983 ± 0.0437\n",
      "[Binary Stage N] recall: 0.7973 ± 0.1031\n",
      "[Binary Stage N] f1: 0.7428 ± 0.0623\n",
      "[Binary Stage N] balanced_accuracy: 0.6721 ± 0.0414\n",
      "[Binary Stage N] log_loss: 0.6357 ± 0.0327\n",
      "[Binary Stage N] roc_auc: 0.7616 ± 0.0301\n",
      "\n",
      "=== Final Model Evaluation ===\n",
      "Final Strategy: refit_full\n",
      "\n",
      "=== Refitting model on the full training + validation dataset ===\n",
      "Training for 3 epochs (based on average from CV).\n",
      "Initialized weights from scratch.\n",
      "[Refit | Epoch 3/3] TrainLoss=0.5588\n",
      "=== Refitting complete ===\n",
      "\n",
      "=== Evaluating on Hold-Out Test Set ===\n",
      "\n",
      "=== Point Estimate Metrics ===\n",
      "[Point Estimate] accuracy: 0.7086\n",
      "[Point Estimate] precision: 0.7256\n",
      "[Point Estimate] recall: 0.9520\n",
      "[Point Estimate] f1: 0.8235\n",
      "[Point Estimate] balanced_accuracy: 0.5260\n",
      "[Point Estimate] log_loss: 0.6140\n",
      "[Point Estimate] roc_auc: 0.6330\n",
      "\n",
      "=== Confidence Intervals ===\n",
      "[Confidence Interval] accuracy: 0.7089 ± 0.0182 [0.6743, 0.7429]\n",
      "[Confidence Interval] precision: 0.7258 ± 0.0103 [0.7073, 0.7469]\n",
      "[Confidence Interval] recall: 0.9524 ± 0.0189 [0.9120, 0.9840]\n",
      "[Confidence Interval] f1: 0.8237 ± 0.0114 [0.8000, 0.8443]\n",
      "[Confidence Interval] balanced_accuracy: 0.5264 ± 0.0233 [0.4840, 0.5740]\n",
      "[Confidence Interval] log_loss: 0.6137 ± 0.0339 [0.5483, 0.6816]\n",
      "[Confidence Interval] roc_auc: 0.6334 ± 0.0475 [0.5384, 0.7240]\n"
     ]
    }
   ],
   "source": [
    "from scripts.train import run_experiment, set_global_seed\n",
    "\n",
    "SEED = 42\n",
    "set_global_seed(SEED)\n",
    "\n",
    "test_metrics, ci_dict, final_model, cv_results = run_experiment(\n",
    "    model_builder=lambda: WSIModel(\n",
    "        input_feature_dim=1536,  # Example input feature dimension\n",
    "        n_classes=n_classes,\n",
    "        encoder_type=encoder_type,\n",
    "        head_dropout=0.35,\n",
    "        head_dim=512,\n",
    "        num_fc_layers=1,\n",
    "        hidden_dim=128,\n",
    "        ds_dropout=0.3,\n",
    "        simple_mlp=False,\n",
    "        freeze_encoder=False,\n",
    "        encoder_attrs=encoder_attrs\n",
    "    ),\n",
    "    preloaded_features=preloaded_features,\n",
    "    train_labels=train_labels,\n",
    "    test_labels=test_labels,\n",
    "    patient_id_mapping=patient_id_mapping,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    task=task,\n",
    "    lr=lr,\n",
    "    l2_reg=l2_reg,\n",
    "    early_stopping=early_stopping,\n",
    "    bag_size=None,\n",
    "    replacement=False,\n",
    "    class_weights=train_class_weights,\n",
    "    key_metric=\"roc_auc\" if n_classes == 2 else \"balanced_accuracy\",\n",
    "    precision=precision,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    accum_steps=accum_steps,\n",
    "    step_on_epochs=step_on_epochs,\n",
    "    preloaded=preloaded,\n",
    "    feature_dir=feature_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20806927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold by Youden's J statistic: 0.6631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def oof_positive_probs(oof_logits):  # torch.Tensor [N,1] or [N,2]\n",
    "    import torch, torch.nn.functional as F\n",
    "    if oof_logits.ndim == 1 or oof_logits.size(1) == 1:\n",
    "        return torch.sigmoid(oof_logits.squeeze(-1)).cpu().numpy()\n",
    "    else:\n",
    "        return F.softmax(oof_logits, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "def tune_threshold_youden(y_true, p1):\n",
    "    fpr, tpr, thr = roc_curve(y_true, p1)\n",
    "    j = tpr - fpr\n",
    "    i = int(np.argmax(j))\n",
    "    # roc_curve returns len(thr)=len(tpr)=len(fpr); thr are decision thresholds on p1\n",
    "    return float(thr[i]), float(j[i])\n",
    "\n",
    "oof = cv_results[\"oof\"]\n",
    "y = oof[\"y\"]\n",
    "p1 = oof_positive_probs(oof[\"logits\"])\n",
    "\n",
    "t_j,   _ = tune_threshold_youden(y, p1)\n",
    "print(f\"Optimal threshold by Youden's J statistic: {t_j:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0ecd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold metrics: {'threshold': 0.6631237864494324, 'sensitivity': np.float64(0.7149999999999982), 'specificity': np.float64(0.6842105263157872), 'ppv': 0.7486910994764397, 'npv': np.float64(0.6459627329192527)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def op_metrics(y_true, p1, t=0.9922):\n",
    "    y_pred = (p1 >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sens = tp / (tp + fn + 1e-12)   # recall\n",
    "    spec = tn / (tn + fp + 1e-12)\n",
    "    ppv  = precision_score(y_true, y_pred, zero_division=0)\n",
    "    npv  = tn / (tn + fn + 1e-12)\n",
    "    return dict(threshold=t, sensitivity=sens, specificity=spec, ppv=ppv, npv=npv)\n",
    "\n",
    "# Make sure p1 are probabilities of the positive class!\n",
    "# p1 = sigmoid(oof_logits.squeeze(1))  # if single-logit\n",
    "# p1 = softmax(oof_logits,1)[:,1]      # if two-logit\n",
    "op_dict = op_metrics(y, p1, t=t_j)\n",
    "print(f\"Optimal threshold metrics: {op_dict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
